{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepLearning import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import treys\n",
    "from treys import Evaluator\n",
    "from treys import Card\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM poker bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so what are we trying to accomplish here.\n",
    "We want to build a naive LSTM poker bot. We need to do three things:\n",
    "\n",
    "- [x] Encode a poker game in a meaningful way\n",
    "\n",
    "- [x] Develop a useful loss metric for games\n",
    "\n",
    "- [x] Test many-to-many or many-to-one models for games\n",
    "\n",
    "Note: the above checkboxes illustrate a CURSORY look at these topics. We will continue to explore them in future games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding a poker game:\n",
    "\n",
    "We're going to approach this by just encoding the cards at each step.\n",
    "There are 4 discrete betting stages that are worth keeping track of in poker:\n",
    "- Pre-Flop\n",
    "- Flop\n",
    "- Turn\n",
    "- River\n",
    "\n",
    "We'll create a `1x4x52` dim tensor to encode all the information in each stage for in one poker game.\n",
    "\n",
    "This way we can create a training dataframe of `N` examples with shape: `Nx4x52`\n",
    "Where `4` again represents the discrete betting stages and `52` is the one hot encoded cards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_staged_games(num_games, device = 'cpu', dtype = torch.float, verbose = False):\n",
    "    to = {'device': device, 'dtype':dtype}\n",
    "    X = []\n",
    "    y = []\n",
    "    for g in range(num_games//2):\n",
    "        start_time = time.time()\n",
    "        if g % verbose == 0:\n",
    "            print(\"Completed {} in {:2f} seconds\".format(verbose, time.time()-start_time))\n",
    "        p1, p2, board = utils.make_heads_up()\n",
    "        g1 = torch.stack(\n",
    "            [\n",
    "                utils.one_hot_cards(p1, **to), \n",
    "                utils.one_hot_cards(board[:3], **to), \n",
    "                utils.one_hot_cards([board[3]], **to),\n",
    "                utils.one_hot_cards([board[4]], **to)\n",
    "            ]\n",
    "        )\n",
    "        g2 = torch.stack(\n",
    "            [\n",
    "                utils.one_hot_cards(p2, **to), \n",
    "                utils.one_hot_cards(board[:3], **to), \n",
    "                utils.one_hot_cards([board[3]], **to),\n",
    "                utils.one_hot_cards([board[4]], **to)\n",
    "            ]\n",
    "        )\n",
    "        X.append(g1)\n",
    "        X.append(g2)\n",
    "        \n",
    "        s1, s2 = utils.score_heads_up(p1, p2, board)\n",
    "        \n",
    "        y.append(torch.tensor(s2, **to)) # if p1 wins append 0 => s2 is 0\n",
    "        y.append(torch.tensor(s1, **to)) # if p1 loses append 1 => s1 is 1\n",
    "        \n",
    "    X = torch.stack(X)\n",
    "    y = torch.stack(y)\n",
    "    \n",
    "    return X, y.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to One architecture experiments:\n",
    "\n",
    "We're going to try to use a Many-to-one LSTM to predict our likelihood of winning a hand.\n",
    "\n",
    "Our approach is as follows:\n",
    "- LSTM with a hidden dimension of 300 (arbitrary)\n",
    "- Output transformation with the following properties:\n",
    "    - Linear layer with input 300 and output 2\n",
    "    - Softmax for thresholding \n",
    "    - First dim of output is likelihood for us to win\n",
    "    - Second dim is likelihood for opponents to win\n",
    "    - This allows us to use `CrossEntropyLoss` as a penalty mechanism (Note we'll have to skip the softmax when we use `CrossEntropyLoss`)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A simpleLSTM for poker\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size = 300):\n",
    "        \"\"\"\n",
    "        hidden_size: size of hidden dimension of LSTM\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTMCell(52, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "        self.squash = nn.Sigmoid()\n",
    "#         self.params = []\n",
    "#         self.params += list(self.lstm.parameters()) + list(self.output.parameters()) + list(self.squash.parameters())\n",
    "        \n",
    "    def forward(self, X, squash = False):\n",
    "        \"\"\"\n",
    "        Forward pass of the LSTM\n",
    "        X: input of shape Nx4x52\n",
    "        squash: whether or not to squash using softmax\n",
    "        \n",
    "        Returns:\n",
    "            tensor of shape Nx2 representing likelihood to win and likelihood for opponent to win.\n",
    "            IF squash==True values represent probabilities.\n",
    "        \"\"\"\n",
    "        N, r, _ = X.shape\n",
    "        \n",
    "        hand = X[:,0]\n",
    "        flop = X[:,1]\n",
    "        turn = X[:,2]\n",
    "        river = X[:,3]\n",
    "        \n",
    "        # now we can pass through:\n",
    "        hidden, cell = torch.zeros(N, 300, dtype=X.dtype, device=X.device), torch.zeros(N, 300, dtype=X.dtype, device=X.device)\n",
    "        \n",
    "        # first round:\n",
    "        hidden, cell = self.lstm(hand, (hidden,cell))\n",
    "        \n",
    "        # second round:\n",
    "        hidden, cell = self.lstm(flop, (hidden, cell))\n",
    "        \n",
    "        # third round:\n",
    "        hidden, cell = self.lstm(turn, (hidden, cell))\n",
    "        \n",
    "        # fourth round:\n",
    "        hidden, cell = self.lstm(river, (hidden, cell))\n",
    "        \n",
    "        #output:\n",
    "        scores = self.output(hidden)\n",
    "        \n",
    "        if squash:\n",
    "            return self.squash(scores)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model, epochs = 10, verbose = False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: training tensor of shape (N,52)\n",
    "        y: target tensor of shape (N,1)\n",
    "        model: a torch.nn.Module model\n",
    "        epochs: number of epochs to train\n",
    "        verbose: iterations of epochs to print out (1 for all, False for none)\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        scores = model(X)\n",
    "        loss = criterion(scores, y)\n",
    "        with torch.no_grad():\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if verbose and e%verbose == 0:\n",
    "                print(\"epoch: {} loss: {:.4f}\".format(e,loss.item()))\n",
    "                \n",
    "def evaluate_model(X, y, model):\n",
    "    with torch.no_grad():\n",
    "        scores = model(X)\n",
    "        #threshold for predictions\n",
    "        scores[scores < 0.5] = 0\n",
    "        scores[scores >= 0.5] = 1\n",
    "        return (scores == y).sum().item()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING THIS TAKES A LONG TIME\n",
    "X_train, y_train = make_staged_games(30000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = make_staged_games(1000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simpleLSTM().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.5587\n",
      "epoch: 100 loss: 0.6666\n",
      "epoch: 200 loss: 0.6477\n",
      "epoch: 300 loss: 0.6878\n",
      "epoch: 400 loss: 0.6623\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train, y_train, model, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(X_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out == y_test).sum().item()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deepLearning/lstmTrain.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deepLearning/lstmTrain_y.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Loss experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to have our model make a many-to-many predictions for each round of the betting.\n",
    "\n",
    "We're going to arbitrarily set the loss penalty to be: `1,2,3,4` corresponding with each round of betting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sequenceLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    A sequence LSTM for choosing to call per round\n",
    "    \"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == torch.nn.LSTMCell:\n",
    "            torch.nn.init.normal_(m.weight_hh)\n",
    "            torch.nn.init.normal_(m.weight_ih)\n",
    "            torch.nn.init.normal_(m.bias_hh)\n",
    "            torch.nn.init.normal_(m.bias_ih)\n",
    "        elif type(m) != torch.nn.Sigmoid and type(m) != sequenceLSTM:\n",
    "            torch.nn.init.normal_(m.weight)\n",
    "            torch.nn.init.normal_(m.bias)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 300\n",
    "        self.lstm = nn.LSTMCell(52, self.hidden_size)\n",
    "        self.output = nn.Linear(self.hidden_size, 2)\n",
    "        self.squash = nn.Sigmoid()\n",
    "        self.penalty = [1,2,3,4]\n",
    "        self.apply(sequenceLSTM.init_weights)\n",
    "    \n",
    "    def forward(self, X): \n",
    "        \"\"\"\n",
    "        X is of shape N, 4, 52\n",
    "        returns a tensor of shape (4) where 0 indicates staying in and 1 indicates folding\n",
    "        \"\"\"\n",
    "        N, _, _ = X.shape\n",
    "        hand = X[:, 0]\n",
    "        flop = X[:, 1] + hand\n",
    "        turn = X[:, 2] + flop\n",
    "        river = X[:, 3] + turn\n",
    "        out = []\n",
    "        \n",
    "        # now each of the objects above is of shape Nx52\n",
    "        hidden, cell = torch.zeros(N, 300, dtype=X.dtype, device=X.device, requires_grad=True), torch.zeros(N, 300, dtype=X.dtype, device=X.device, requires_grad=True)\n",
    "        \n",
    "        #pre-flop:\n",
    "        hidden, cell = self.lstm(hand, (hidden, cell))\n",
    "        score = self.squash(self.output(hidden))\n",
    "        out.append(score)\n",
    "        \n",
    "        #flop:\n",
    "        hidden, cell = self.lstm(flop, (hidden, cell))\n",
    "        score = self.squash(self.output(hidden))\n",
    "        out.append(score)\n",
    "        \n",
    "        #turn:\n",
    "        hidden, cell = self.lstm(turn, (hidden, cell))\n",
    "        score = self.squash(self.output(hidden))\n",
    "        out.append(score)\n",
    "        \n",
    "        #river:\n",
    "        hidden, cell = self.lstm(river, (hidden, cell))\n",
    "        score = self.squash(self.output(hidden))\n",
    "        out.append(score)\n",
    "        \n",
    "        return torch.stack(out, 1) #should be of shape Nx4\n",
    "    \n",
    "    def calc_loss(self, X, y, mode = 'house'):\n",
    "        if mode != 'house' and mode != 'player':\n",
    "            raise Exception(\"mode must be of type {} or {}\".format('house', 'player'))\n",
    "        output = self.forward(X) # of shape Nx4\n",
    "        scoring = torch.tensor([1,2,3,4]).reshape(-1,4).to('cuda')\n",
    "        scoring = ((y * -2) + 1).to(torch.float).reshape(-1, 1) * scoring\n",
    "        output[:,:,0] *= -1\n",
    "        loss = (output*scoring.unsqueeze(2)).sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = utils.make_staged_games(1000, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequenceLSTM().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sequence(X, y, model, epochs = 10, batch_size = 10000, verbose = False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: training tensor of shape (N,52)\n",
    "        y: target tensor of shape (N,1)\n",
    "        model: a torch.nn.Module model\n",
    "        epochs: number of epochs to train\n",
    "        verbose: iterations of epochs to print out (1 for all, False for none)\n",
    "    \"\"\"\n",
    "    # shuffle dataset:\n",
    "    X_train, y_train\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "    optimizer.zero_grad()\n",
    "    for e in range(epochs):\n",
    "        loss = model.calc_loss(X, y)\n",
    "        with torch.no_grad():\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if verbose and e%verbose == 0:\n",
    "                print(\"epoch: {} loss: {:.4f}\".format(e,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: -7659.9150\n",
      "epoch: 1 loss: -7754.9209\n",
      "epoch: 2 loss: -7838.3247\n",
      "epoch: 3 loss: -7895.5728\n",
      "epoch: 4 loss: -7954.4590\n",
      "epoch: 5 loss: -7996.0518\n",
      "epoch: 6 loss: -8037.0791\n",
      "epoch: 7 loss: -8081.0586\n",
      "epoch: 8 loss: -8113.9155\n",
      "epoch: 9 loss: -8139.6133\n",
      "epoch: 10 loss: -8169.6821\n",
      "epoch: 11 loss: -8197.6582\n",
      "epoch: 12 loss: -8225.1846\n",
      "epoch: 13 loss: -8257.2207\n",
      "epoch: 14 loss: -8281.8223\n",
      "epoch: 15 loss: -8305.7480\n",
      "epoch: 16 loss: -8330.6963\n",
      "epoch: 17 loss: -8358.5781\n",
      "epoch: 18 loss: -8381.5312\n",
      "epoch: 19 loss: -8415.0166\n",
      "epoch: 20 loss: -8436.6162\n",
      "epoch: 21 loss: -8461.4336\n",
      "epoch: 22 loss: -8485.6797\n",
      "epoch: 23 loss: -8508.7012\n",
      "epoch: 24 loss: -8537.4785\n",
      "epoch: 25 loss: -8565.1387\n",
      "epoch: 26 loss: -8583.5215\n",
      "epoch: 27 loss: -8600.7129\n",
      "epoch: 28 loss: -8622.8008\n",
      "epoch: 29 loss: -8643.5820\n",
      "epoch: 30 loss: -8657.9766\n",
      "epoch: 31 loss: -8675.3818\n",
      "epoch: 32 loss: -8690.1953\n",
      "epoch: 33 loss: -8709.2559\n",
      "epoch: 34 loss: -8733.0752\n",
      "epoch: 35 loss: -8757.4922\n",
      "epoch: 36 loss: -8777.1172\n",
      "epoch: 37 loss: -8793.7871\n",
      "epoch: 38 loss: -8810.2949\n",
      "epoch: 39 loss: -8824.3711\n",
      "epoch: 40 loss: -8841.4062\n",
      "epoch: 41 loss: -8854.8799\n",
      "epoch: 42 loss: -8867.4248\n",
      "epoch: 43 loss: -8881.8008\n",
      "epoch: 44 loss: -8896.9395\n",
      "epoch: 45 loss: -8910.0332\n",
      "epoch: 46 loss: -8922.4209\n",
      "epoch: 47 loss: -8934.4746\n",
      "epoch: 48 loss: -8943.9639\n",
      "epoch: 49 loss: -8954.4414\n"
     ]
    }
   ],
   "source": [
    "train_sequence(X_train, y_train, seq, 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(player_score, bot_score):\n",
    "    player1, bot, board = utils.make_heads_up()\n",
    "    bot_treys = utils.make_treys(bot)\n",
    "    player1 = utils.make_treys(player1)\n",
    "    board_treys = utils.make_treys(board)\n",
    "    print(\"Your Cards:{} \".format(Card.print_pretty_cards(player1)))\n",
    "    bot_encoded = torch.stack([utils.one_hot_cards(bot), utils.one_hot_cards(board[:3]), utils.one_hot_cards([board[3]]), utils.one_hot_cards([board[4]])]).unsqueeze(0).to('cuda')\n",
    "    bot_bets = seq.forward(bot_encoded).argmax(2).squeeze()\n",
    "    bet = input(\"It costs 1 to call (y/n)\")\n",
    "    if bet != 'y':\n",
    "        print(\"You folded and lost 0.\")\n",
    "        return (player_score, bot_score)\n",
    "    if bot_bets[0] == 1:\n",
    "        print(\"Bot folded with {} you win 0\".format(Card.print_pretty_cards(utils.make_treys(bot))))\n",
    "        return (player_score, bot_score)\n",
    "    print(\"Bot calls 1. Pot is 2\")\n",
    "    print(\"Flop:{}\".format(Card.print_pretty_cards(board_treys[:3])))\n",
    "    # flop bet\n",
    "    if bot_bets[1] == 0:\n",
    "        print(\"Bot raises 2\")\n",
    "    else:\n",
    "        print(\"Bot folds with {} you win 1!\".format(Card.print_pretty_cards(utils.make_treys(bot))))\n",
    "        return (player_score+1, bot_score-1)\n",
    "    bet = input(\"It costs 2 to call (y/n)\")\n",
    "    if bet != 'y':\n",
    "        print(\"You lost 1 token\")\n",
    "        return (player_score-1, bot_score+1)\n",
    "    #turn bet\n",
    "    print(\"Turn:{}\".format(Card.print_pretty_card(board_treys[3])))\n",
    "    bet = input(\"Pot is 6. It is 3 to call (y/n)\")\n",
    "    if bet!= 'y':\n",
    "        print(\"You lost 3 tokens\")\n",
    "        return (player_score-3, bot_score+3)\n",
    "    if bot_bets[2] == 0:\n",
    "        print(\"Bot calls 3. Pot is now 12.\")\n",
    "    else:\n",
    "        print(\"Bot folds with {} You win a pot worth 6 tokens.\".format(Card.print_pretty_cards(utils.make_treys(bot))))\n",
    "        return (player_score+3, bot_score-3)\n",
    "    #river bet\n",
    "    print(\"River:{}\".format(Card.print_pretty_card(board_treys[4])))\n",
    "    if bot_bets[3] == 0:\n",
    "        print(\"Bot raises 4. Pot is now 20.\")\n",
    "    else:\n",
    "        print(\"Bot folds with {} You win a pot worth 12 tokens.\".format(Card.print_pretty_cards(utils.make_treys(bot))))\n",
    "        return (player_score-6, bot_score+6)\n",
    "    bet = input(\"It is 4 to call (y/n)\")\n",
    "    if bet != 'y':\n",
    "        print(\"You've lost 6 tokens.\")\n",
    "        return (player_score-6, bot_score+6)\n",
    "    e = Evaluator()\n",
    "    if e.evaluate(board_treys, player1) < e.evaluate(board_treys, bot_treys):\n",
    "        print(\"You win a pot of 20!\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n",
    "        return (player_score+10, bot_score-10)\n",
    "    elif e.evaluate(board_treys, player1) > e.evaluate(board_treys, bot_treys):\n",
    "        print(\"You lose a pot of 20.\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n",
    "        return (player_score-10, bot_score+10)\n",
    "    else:\n",
    "        print(\"You push a pot of 20 taking home 10.\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n",
    "        return (player_score, bot_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Cards: [4♠],[J♥]  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It costs 1 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot calls 1. Pot is 2\n",
      "Flop: [4♥],[5♥],[7♣] \n",
      "Bot folds with  [3♦],[3♥]  you win 1!\n"
     ]
    }
   ],
   "source": [
    "play_game(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load the bigger training set:\n",
    "with open('./deepLearning/data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "with open('./deepLearning/data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 4, 52])\n",
      "torch.Size([1000000])\n"
     ]
    }
   ],
   "source": [
    "X = X.to('cpu')\n",
    "y = y.to('cpu')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to use batchwise trainning here so:\n",
    "def get_batch(X, y, batch_size):\n",
    "    mask = torch.randint(0, X.shape[0], (batch_size, 1))\n",
    "    return X[mask].squeeze(1).to('cuda'), y[mask].squeeze(1).to('cuda')\n",
    "\n",
    "def train_sequence(X, y, model, epochs = 10, batch_size = 10000, verbose = False, deepVerbose = False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: training tensor of shape (N,52)\n",
    "        y: target tensor of shape (N,1)\n",
    "        model: a torch.nn.Module model\n",
    "        epochs: number of epochs to train\n",
    "        verbose: iterations of epochs to print out (1 for all, False for none)\n",
    "    \"\"\"\n",
    "    if not verbose:\n",
    "        deepVerbose = False\n",
    "    if verbose:\n",
    "        print(\"Training on {} samples across {} batches per epoch\".format(X.shape[0], X.shape[0]//batch_size))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "    optimizer.zero_grad()\n",
    "    for e in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        for b in range(X.shape[0]//batch_size):\n",
    "            X_train, y_train = get_batch(X, y, batch_size)\n",
    "            loss = model.calc_loss(X_train, y_train)\n",
    "            with torch.no_grad():\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                epoch_loss += loss.item()\n",
    "                optimizer.step()\n",
    "                if deepVerbose and b%deepVerbose == 0:\n",
    "                    print(\"batch: {} loss: {:.4f}\".format(b,loss.item()))\n",
    "        if verbose and e%verbose == 0:\n",
    "            print(\"epoch: {} loss: {:.4f}\".format(e,epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequenceLSTM().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1000000 samples across 20 batches per epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052bb1c7bf6c413093d6a3e82a4a6625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: -4371264.6719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-5b36175a008a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-3ad26d5c12b5>\u001b[0m in \u001b[0;36mtrain_sequence\u001b[0;34m(X, y, model, epochs, batch_size, verbose, deepVerbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdeepVerbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdeepVerbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sequence(X,y, seq, 100, 50000, 20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Bets tensor([1, 0, 0, 1], device='cuda:0')\n",
      "You lose a pot of 20.\n",
      "Your hand was: [5♦],[7♦] \n",
      "Bot hand was: [T♥],[7♣] \n",
      "Board was [8♥],[K♥],[9♣],[2♥],[J♣] \n"
     ]
    }
   ],
   "source": [
    "player1, bot, board = utils.make_heads_up()\n",
    "bot_treys = utils.make_treys(bot)\n",
    "player1 = utils.make_treys(player1)\n",
    "board_treys = utils.make_treys(board)\n",
    "bot_encoded = torch.stack([utils.one_hot_cards(bot), utils.one_hot_cards(board[:3]), utils.one_hot_cards([board[3]]), utils.one_hot_cards([board[4]])]).unsqueeze(0).to('cuda')\n",
    "bot_bets = seq.forward(bot_encoded).argmax(2).squeeze()\n",
    "print('Bot Bets {}'.format(bot_bets))\n",
    "e = Evaluator()\n",
    "if e.evaluate(board_treys, player1) < e.evaluate(board_treys, bot_treys):\n",
    "    print(\"You win a pot of 20!\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n",
    "elif e.evaluate(board_treys, player1) > e.evaluate(board_treys, bot_treys):\n",
    "    print(\"You lose a pot of 20.\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n",
    "else:\n",
    "    print(\"You push a pot of 20 taking home 10.\\nYour hand was:{}\\nBot hand was:{}\\nBoard was{}\".format(Card.print_pretty_cards(player1), Card.print_pretty_cards(bot_treys), Card.print_pretty_cards(board_treys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "player, bot = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Cards: [5♣],[J♠]  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It costs 1 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot calls 1. Pot is 2\n",
      "Flop: [A♠],[4♠],[A♥] \n",
      "Bot raises 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It costs 2 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn:[4♦]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pot is 6. It is 3 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot calls 3. Pot is now 12.\n",
      "River:[T♥]\n",
      "Bot raises 4. Pot is now 20.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It is 4 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You win a pot of 20!\n",
      "Your hand was: [5♣],[J♠] \n",
      "Bot hand was: [8♠],[7♦] \n",
      "Board was [A♠],[4♠],[A♥],[4♦],[T♥] \n"
     ]
    }
   ],
   "source": [
    "player, bot = play_game(player, bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132, 68\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, {}\".format(player, bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Cards: [7♠],[8♠]  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It costs 1 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot calls 1. Pot is 2\n",
      "Flop: [4♥],[A♦],[7♦] \n",
      "Bot raises 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It costs 2 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn:[A♥]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pot is 6. It is 3 to call (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot folds with  [T♣],[Q♦]  You win a pot worth 6 tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, -1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_game(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
